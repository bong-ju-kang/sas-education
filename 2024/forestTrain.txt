rf = cas.decisionTree.forestTrain(

    # 결정나무와 동일한 공통옵션
    # 훈련 데이터 지정
    table = {'name':'df_partn_impute', 'caslib':'casuser', 'where':'_PartInd_=1'},

    # 입력 변수 지정
    inputs=imp_xvars,

    # 목표 변수 지정
    target=target,

    # 범주 변수 지정
    nominals=imp_cats + [target],

    # 연속 변수의 범주 개수 지정
    nBins=20,

    # 최소 나무의 크기
    leafSize=5,

    # 나무의 최대 깊이
    maxLevel=10,

    # 가지 분기 기준
    crit="GAIN",

    # 가지 치기 여부
    prune=True,

    # 변수 중요도 출력 여부
    varImp=True,

    #
    # 랜덤 포레스트 초모수
    #
    # 씨앗값
    seed = 123,
    
    # 붓스트랩 표본 비율
    bootstrap=0.6,
    
    # 결정나무의 개수
    nTree=200,
    
    # 분기 시에 사용하는 변수의 개수: 기본값은 변수 개수의 제곱근
    m=7, 

    # 각 노드(잎)에서 예측되는 값: 확률
    vote="PROB",

    # 가방밖 오차 출력 여부
    OOB=True,

    # 결과 저장:   ASTORE
    savestate={"name": "forest_model", "replace": True}
)